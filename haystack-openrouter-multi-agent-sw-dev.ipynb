{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a61f97e",
   "metadata": {},
   "source": [
    "## Sistema Multi-Agente per lo Sviluppo Software con Haystack\n",
    "\n",
    "Questo notebook implementa un **sistema multi-agente** bassu su **Haystack** e integrato con **OpenRouter.AI**, in cui più **modelli linguistici di grandi dimensioni (LLM)** collaborano in modo coordinato, ciascuno con un **ruolo specifico** all'interno del ciclo di vita di un progetto software.  \n",
    "L'obiettivo è simulare un team di sviluppo virtuale in grado di gestire un progetto software dall'analisi iniziale fino alla verifica finale.\n",
    "\n",
    "---\n",
    "\n",
    "### 👥 Ruoli e Responsabilità\n",
    "\n",
    "- **Project Manager**\n",
    "- **Solution Architect**\n",
    "- **Technical Lead**\n",
    "- **Frontend Developer**\n",
    "- **Backend Developer**\n",
    "- **Database Administrator**\n",
    "- **QA & Test Engineer**\n",
    "\n",
    "---\n",
    "\n",
    "### 🔁 Flusso del Processo Collaborativo\n",
    "\n",
    "```text\n",
    "Project Manager → Solution Architect → Technical Lead\n",
    "                              ↓\n",
    "       Frontend Dev ←→ Backend Dev ←→ DB Admin\n",
    "                              ↓\n",
    "                     QA & Test Engineer\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🧭 Descrizione del Processo\n",
    "\n",
    "- Il **Project Manager** riceve in input i parametri utente (`project_name`, `project_type`, `project_requirements`) e redige un documento di *Specifiche di Progetto*.\n",
    "- Il **Solution Architect** definisce l'architettura tecnica del sistema, selezionando i componenti principali e le linee guida progettuali.\n",
    "- Il **Technical Lead** costruisce un *piano di implementazione* articolato in un backlog di attività, assegnando priorità, responsabili e dipendenze.\n",
    "- Gli sviluppatori **Frontend**, **Backend** e il **Database Administrator** realizzano le varie componenti applicative seguendo il piano stabilito.\n",
    "- Il **QA & Test Engineer** verifica la correttezza, la robustezza e la coerenza delle implementazioni rispetto ai requisiti iniziali e alle specifiche tecniche.\n",
    "\n",
    "I deliverables prodotti da ogni agent vengono salvati in formato MarkDown nella cartella /outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b863f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "from haystack import Pipeline\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.utils import Secret\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Caricamento variabili d'ambiente\n",
    "load_dotenv(\"vars.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0764e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri del progetto\n",
    "project_name = \"ToDo list per la gestione di attività personali\"\n",
    "project_type = \"Web App\"\n",
    "project_requirements = [\n",
    "    # Requisiti Funzionali\n",
    "    \"L'utente può creare nuove attività con titolo, descrizione, data di scadenza e priorità\",\n",
    "    \"Le attività devono essere visualizzabili in una lista ordinabile per data, priorità o stato\",\n",
    "    \"L'utente può modificare attività esistenti (titolo, descrizione, scadenza, priorità)\",\n",
    "    \"L'utente può eliminare attività dalla lista\",\n",
    "    \"L'utente può contrassegnare un'attività come completata\",\n",
    "    \"È possibile filtrare le attività per stato (completate/in sospeso), priorità e cercarle per testo\",\n",
    "    \"Il sistema può inviare notifiche per attività prossime alla scadenza\",\n",
    "    \"Le attività possono essere assegnate a categorie personalizzate o etichette (tag)\",\n",
    "    \"Il software consente di salvare e ripristinare le attività (backup locale o cloud)\",\n",
    "    \"Le attività si sincronizzano tra più dispositivi con lo stesso account\",\n",
    "   \n",
    "    # Requisiti Non Funzionali\n",
    "    \"Interfaccia semplice, intuitiva e usabile anche da utenti non esperti\",\n",
    "    \"Tempi di risposta rapidi anche con molte attività\",\n",
    "    \"Supporto per più piattaforme (desktop, mobile, web)\",\n",
    "    \"Il sistema garantisce l'integrità e la persistenza dei dati inseriti\",\n",
    "    \"I dati dell'utente devono essere protetti, soprattutto se salvati nel cloud\",\n",
    "    \"Il software deve essere scalabile per l'aggiunta futura di nuove funzionalità\",\n",
    "\n",
    "    # Requisiti Tecnici\n",
    "    \"Supporto per frontend in React, Angular, Vue o Flutter\",\n",
    "    \"Utilizzo di backend in Node.js, Python (Django/Flask) o Java (Spring Boot)\",\n",
    "    \"Persistenza dati locale (SQLite) o remota tramite API REST e database relazionale\",\n",
    "    \"Architettura del software basata su MVC o MVVM\",\n",
    "    \"Integrazione con notifiche push (Firebase, OneSignal) e autenticazione (OAuth, Google Sign-In)\",\n",
    "    \"Presenza di test unitari e di integrazione per garantire la qualità del software\"       \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agent_class_definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HaystackAgent:\n",
    "    \"\"\"Classe per rappresentare un agente nel sistema Haystack\"\"\"\n",
    "    \n",
    "    def __init__(self, role: str, goal: str, backstory: str, llm_config: dict = None, verbose: bool = False):\n",
    "        self.role = role\n",
    "        self.goal = goal\n",
    "        self.backstory = backstory\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Configurazione di default per llm_config\n",
    "        default_llm_config = {\n",
    "            \"model\": \"openai/gpt-3.5-turbo\",\n",
    "            \"temperature\": 0.7\n",
    "        }\n",
    "        \n",
    "        self.llm_config = llm_config or default_llm_config\n",
    "        \n",
    "          # Creazione del generatore OpenAI con Secret per l'API key\n",
    "        api_key_value = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not api_key_value:\n",
    "            raise ValueError(\"OPENAI_API_KEY non trovata nelle variabili d'ambiente\")\n",
    "        \n",
    "        self.generator = OpenAIGenerator(\n",
    "            api_key=Secret.from_token(api_key_value),  # Usa Secret.from_token() invece di passare direttamente la stringa\n",
    "            api_base_url=os.getenv(\"OPENAI_API_BASE\"),\n",
    "            model=self.llm_config[\"model\"],\n",
    "            generation_kwargs={\n",
    "                \"temperature\": self.llm_config[\"temperature\"]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Template del prompt per l'agente\n",
    "        self.prompt_template = \"\"\"\n",
    "        Ruolo: {{ role }}\n",
    "        Obiettivo: {{ goal }}\n",
    "        Contesto: {{ backstory }}\n",
    "        \n",
    "        Task da eseguire: {{ task_description }}\n",
    "        \n",
    "        {% if context_data %}\n",
    "        Informazioni di contesto dai task precedenti:\n",
    "        {{ context_data }}\n",
    "        {% endif %}\n",
    "        \n",
    "        {% if expected_output %}\n",
    "        Output atteso: {{ expected_output }}\n",
    "        {% endif %}\n",
    "        \n",
    "        {% if project_name %}\n",
    "        Nome del progetto: {{ project_name }}\n",
    "        {% endif %}\n",
    "        \n",
    "        {% if project_type %}\n",
    "        Tipo di progetto: {{ project_type }}\n",
    "        {% endif %}\n",
    "        \n",
    "        {% if project_requirements %}\n",
    "        Requisiti del progetto:\n",
    "        {% for req in project_requirements %}\n",
    "        - {{ req }}\n",
    "        {% endfor %}\n",
    "        {% endif %}\n",
    "        \n",
    "        Fornisci una risposta dettagliata e professionale secondo il tuo ruolo.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Creazione della pipeline\n",
    "        self.pipeline = Pipeline()\n",
    "        prompt_builder = PromptBuilder(template=self.prompt_template)\n",
    "        \n",
    "        self.pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "        self.pipeline.add_component(\"generator\", self.generator)\n",
    "        \n",
    "        self.pipeline.connect(\"prompt_builder\", \"generator\")\n",
    "    \n",
    "    def execute_task(self, task_description: str, expected_output: str = \"\", \n",
    "                    context_data: str = \"\", **kwargs) -> str:\n",
    "        \"\"\"Esegue un task utilizzando l'agente\"\"\"\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"[{self.role}] Eseguendo task: {task_description[:100]}...\")\n",
    "        \n",
    "        result = self.pipeline.run({\n",
    "            \"prompt_builder\": {\n",
    "                \"role\": self.role,\n",
    "                \"goal\": self.goal,\n",
    "                \"backstory\": self.backstory,\n",
    "                \"task_description\": task_description,\n",
    "                \"expected_output\": expected_output,\n",
    "                \"context_data\": context_data,\n",
    "                **kwargs\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        response = result[\"generator\"][\"replies\"][0]\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"[{self.role}] Task completato.\")\n",
    "        \n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task_class_definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HaystackTask:\n",
    "    \"\"\"Classe per rappresentare un task nel sistema Haystack\"\"\"\n",
    "    \n",
    "    def __init__(self, description: str, agent: HaystackAgent, expected_output: str = \"\", \n",
    "                 context_tasks: List['HaystackTask'] = None, output_file: str = \"\"):\n",
    "        self.description = description\n",
    "        self.agent = agent\n",
    "        self.expected_output = expected_output\n",
    "        self.context_tasks = context_tasks or []\n",
    "        self.output_file = output_file\n",
    "        self.output = None\n",
    "        self.executed = False\n",
    "    \n",
    "    def execute(self, **kwargs) -> str:\n",
    "        \"\"\"Esegue il task\"\"\"\n",
    "        if self.executed:\n",
    "            return self.output\n",
    "        \n",
    "        # Raccoglie i risultati dai task di contesto\n",
    "        context_data = \"\"\n",
    "        if self.context_tasks:\n",
    "            context_outputs = []\n",
    "            for ctx_task in self.context_tasks:\n",
    "                if not ctx_task.executed:\n",
    "                    ctx_task.execute(**kwargs)\n",
    "                context_outputs.append(f\"Output da {ctx_task.agent.role}: {ctx_task.output}\")\n",
    "            context_data = \"\\n\\n\".join(context_outputs)\n",
    "        \n",
    "        # Esegue il task\n",
    "        self.output = self.agent.execute_task(\n",
    "            task_description=self.description,\n",
    "            expected_output=self.expected_output,\n",
    "            context_data=context_data,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        self.executed = True\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8128ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_agents(path) -> Dict[str, HaystackAgent]:\n",
    "    \"\"\"Carica la configurazione degli agenti dal file YAML\"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    \n",
    "    agents = {}\n",
    "    \n",
    "    for key, cfg in data.items():\n",
    "        # Configurazione di default per llm_config\n",
    "        default_llm_config = {\n",
    "            \"model\": \"openai/gpt-3.5-turbo\",\n",
    "            \"temperature\": 0.7\n",
    "        }\n",
    "        \n",
    "        llm_config = cfg.get(\"llm_config\", default_llm_config)\n",
    "        \n",
    "        agent = HaystackAgent(\n",
    "            role=cfg[\"role\"],\n",
    "            goal=cfg[\"goal\"],\n",
    "            backstory=cfg[\"backstory\"],\n",
    "            llm_config=llm_config,\n",
    "            verbose=cfg.get(\"verbose\", False)\n",
    "        )\n",
    "        agents[key] = agent\n",
    "    \n",
    "    return agents\n",
    "\n",
    "def load_tasks(path, agents_dict: Dict[str, HaystackAgent]) -> List[HaystackTask]:\n",
    "    \"\"\"Carica la configurazione dei task dal file YAML\"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = yaml.safe_load(f)\n",
    "\n",
    "    task_objs = {}\n",
    "    \n",
    "    # Prima passata: crea tutti i task\n",
    "    for key, cfg in data.items():\n",
    "        agent = agents_dict[cfg[\"agent\"]]\n",
    "        task = HaystackTask(\n",
    "            description=cfg[\"description\"],\n",
    "            expected_output=cfg.get(\"expected_output\", \"\"),\n",
    "            agent=agent,\n",
    "            output_file=cfg.get(\"output_file\", f\"outputs/{key}.md\")\n",
    "        )\n",
    "        task_objs[key] = task\n",
    "\n",
    "    # Seconda passata: imposta le dipendenze di contesto\n",
    "    for key, cfg in data.items():\n",
    "        if \"context\" in cfg:\n",
    "            task_objs[key].context_tasks = [task_objs[cid] for cid in cfg[\"context\"]]\n",
    "\n",
    "    return list(task_objs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crew_class_definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HaystackCrew:\n",
    "    \"\"\"Classe per coordinare l'esecuzione dei task multi-agente\"\"\"\n",
    "    \n",
    "    def __init__(self, agents: List[HaystackAgent], tasks: List[HaystackTask], verbose: bool = False):\n",
    "        self.agents = agents\n",
    "        self.tasks = tasks\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def kickoff(self, inputs: Dict[str, Any]) -> str:\n",
    "        \"\"\"Avvia l'esecuzione di tutti i task\"\"\"\n",
    "        if self.verbose:\n",
    "            print(\"Avvio del sistema multi-agente Haystack...\")\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for i, task in enumerate(self.tasks):\n",
    "            if self.verbose:\n",
    "                print(f\"\\nEseguendo task {i+1}/{len(self.tasks)}: {task.agent.role}\")\n",
    "            \n",
    "            result = task.execute(**inputs)\n",
    "            results.append(result)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"Task {i+1} completato.\")\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"\\nTutti i task sono stati completati!\")\n",
    "        \n",
    "        # Restituisce l'output dell'ultimo task\n",
    "        return results[-1] if results else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f4874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento degli agenti e dei task\n",
    "agents = load_agents(\"agents.yaml\")\n",
    "tasks = load_tasks(\"tasks.yaml\", agents)\n",
    "\n",
    "print(f\"Caricati {len(agents)} agenti e {len(tasks)} task.\")\n",
    "print(\"\\nAgenti disponibili:\")\n",
    "for key, agent in agents.items():\n",
    "    print(f\"- {key}: {agent.role}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8691997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione del crew Haystack\n",
    "crew = HaystackCrew(\n",
    "    agents=list(agents.values()),\n",
    "    tasks=tasks,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e524d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri di input per il sistema\n",
    "inputs = {\n",
    "    'project_name': project_name,\n",
    "    'project_type': project_type,\n",
    "    'project_requirements': project_requirements\n",
    "}\n",
    "\n",
    "print(\"Parametri del progetto:\")\n",
    "print(f\"Nome: {project_name}\")\n",
    "print(f\"Tipo: {project_type}\")\n",
    "print(f\"Numero di requisiti: {len(project_requirements)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5748873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esecuzione del sistema multi-agente\n",
    "print(\"Avvio dell'esecuzione del sistema multi-agente...\\n\")\n",
    "\n",
    "result = crew.kickoff(inputs=inputs)\n",
    "\n",
    "print(\"\\n=== RISULTATO FINALE ===\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b40ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_task_outputs(tasks: List[HaystackTask]):\n",
    "    \"\"\"Salva gli output di tutti i task nei rispettivi file\"\"\"\n",
    "    print(\"\\nSalvataggio degli output...\")\n",
    "    \n",
    "    for task in tasks:\n",
    "        if not task.executed or not task.output:\n",
    "            continue\n",
    "            \n",
    "        filepath = task.output_file\n",
    "        if not filepath:\n",
    "            # Se non c'è output_file, genera un nome dal ruolo dell'agente\n",
    "            name = task.agent.role.lower().replace(\" \", \"_\")\n",
    "            filepath = f\"outputs/{name}_output.md\"\n",
    "        \n",
    "        # Crea la directory se non esiste\n",
    "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "        \n",
    "        # Salva l'output\n",
    "        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "            # Aggiungi un header con informazioni sul task\n",
    "            f.write(f\"# Output da: {task.agent.role}\\n\\n\")\n",
    "            f.write(f\"**Obiettivo:** {task.agent.goal}\\n\\n\")\n",
    "            f.write(f\"**Task:** {task.description}\\n\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "            f.write(task.output)\n",
    "        \n",
    "        print(f\"✓ Salvato: {filepath}\")\n",
    "\n",
    "# Salva tutti gli output\n",
    "save_task_outputs(tasks)\n",
    "print(\"\\nTutti gli output sono stati salvati nella cartella 'outputs/'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riepilogo dell'esecuzione\n",
    "print(\"\\n=== RIEPILOGO ESECUZIONE ===\")\n",
    "print(f\"Progetto: {project_name}\")\n",
    "print(f\"Tipo: {project_type}\")\n",
    "print(f\"Agenti utilizzati: {len(agents)}\")\n",
    "print(f\"Task eseguiti: {len([t for t in tasks if t.executed])}\")\n",
    "print(f\"File generati: {len([t for t in tasks if t.executed and t.output])}\")\n",
    "\n",
    "print(\"\\nTask eseguiti:\")\n",
    "for i, task in enumerate(tasks):\n",
    "    status = \"✓\" if task.executed else \"✗\"\n",
    "    print(f\"{status} {i+1}. {task.agent.role}: {task.description[:80]}...\")\n",
    "\n",
    "print(\"\\nSistema multi-agente Haystack completato con successo!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
